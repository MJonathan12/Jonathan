# Logistic Regression

# Set working directory

setwd("C:\\Users\\ABDL340\\Documents\\Timiza cross-sell to BBK")

 

# Importing the dataset

dataset = read.csv('Combined Data.csv')

str(dataset)

 

# Remove blank values for client ID

library(dplyr)

dataset <- dataset %>%

        filter(!is.na(dataset$Client.Number))

 

dataset$Client.Number <- as.character(dataset$Client.Number)

dataset$Average.overdue.balance <- as.numeric(dataset$Average.overdue.balance)

dataset$Loan.Amount <- as.numeric(dataset$Loan.Amount)

dataset$Interest.earned <- as.numeric(dataset$Interest.earned)

dataset$Registered_CASA <- as.character(dataset$Registered_CASA)

 

str(dataset)

 

dataset <- dataset[, 2:13]

 

# Filtering the contacted customers - BBK_R and BBK_NR

# library(dplyr)

dataset_C <- dataset %>%

        filter(Registered_CASA == "BBK_NR" | Registered_CASA == "BBK_R" )

 

# Count NA values in grades

sum(is.na(dataset_C$Grades))

 

# Drop the Grades columnn due to NA values

dataset_C$Grades <- NULL

head(dataset_C)

 

# Encode the Registered_CASA column

dataset_C$Registered_CASA = factor(dataset_C$Registered_CASA,

                   levels = c('BBK_R', 'BBK_NR'),

                   labels = c(1, 0))

# str(dataset_C)

# summary(dataset_C$Registered_CASA)

 

# Splitting the dataset into the Training set and Test set

# install.packages('caTools')

library(caTools)

set.seed(123)

split = sample.split(dataset_C$Registered_CASA, SplitRatio = 0.8)

training_set = subset(dataset_C, split == TRUE)

test_set = subset(dataset_C, split == FALSE)

 

# Feature Scaling

training_set[, 1:10] = scale(training_set[,1:10])

test_set[, 1:10] = scale(test_set[, 1:10])

 

# Fitting Logistic Regression to the Training set

classifier = glm(formula = Registered_CASA ~ .,

                 family = binomial,

                 data = training_set)

 

# Predicting the Test set results

prob_pred = predict(classifier, type = 'response', newdata = test_set[-11])

y_pred = ifelse(prob_pred > 0.5, 1, 0)

 

# Making the Confusion Matrix

cm = table(test_set[, 10], y_pred > 0.5)

 

table(test_set$Registered_CASA, y_pred)

 

 

# Applying k-Fold Cross Validation

# install.packages('caret')

library(caret)

folds = createFolds(training_set$Registered_CASA, k = 10)

cv = lapply(folds, function(x) {

  training_fold = training_set[-x, ]

  test_fold = training_set[x, ]

  classifier = glm(data = training_set,

                   formula = Registered_CASA ~ .,

                   family = binomial)

  y_pred = predict(classifier, newdata = test_fold[-11])

  y_pred = (y_pred >= 0.5)

  cm = table(test_fold[, 11], y_pred)

  accuracy = (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] + cm[1,2] + cm[2,1])

  return(accuracy)

})

accuracy = mean(as.numeric(cv))

accuracy

# Accuracy is 72.56%

 

# Predicting the behaviour of the rest of the BBK_NC customers

# Filter the BBK_NC customers

dataset_NC <- dataset %>%

  filter(Registered_CASA == "BBK_NC")

 

 

# Feature Scaling

dataset_NC[, 3:12] = scale(dataset_NC[,3:12])

 

prob_pred = predict(classifier, type = 'response', newdata = dataset_NC[3:12])

y_pred = ifelse(prob_pred > 0.5, 1, 0)

 

predicted_values <- as.data.frame(y_pred)

 

dataset_NC$Predicted <- predicted_values

 

# Count BBK_R predicted values in grades

dataset_NC_N <- dataset_NC %>%

  filter(Predicted == "0")

 

 
